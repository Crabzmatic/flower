{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31ed135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9881731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network architecture.\n",
    "\n",
    "    As described in McMahan 2017 paper :\n",
    "\n",
    "    [Communication-Efficient Learning of Deep Networks from\n",
    "    Decentralized Data] (https://arxiv.org/pdf/1602.05629.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes: int = 10) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass of the CNN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input Tensor that will pass through the network\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The resulting Tensor after it has passed through the network\n",
    "        \"\"\"\n",
    "        output_tensor = F.relu(self.conv1(input_tensor))\n",
    "        output_tensor = self.pool(output_tensor)\n",
    "        output_tensor = F.relu(self.conv2(output_tensor))\n",
    "        output_tensor = self.pool(output_tensor)\n",
    "        output_tensor = torch.flatten(output_tensor, 1)\n",
    "        output_tensor = F.relu(self.fc1(output_tensor))\n",
    "        output_tensor = self.fc2(output_tensor)\n",
    "        return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff500c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec2fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for layer in model.parameters():\n",
    "    reshape_tensor = torch.flatten(layer.data)\n",
    "#     print(reshape_tensor)\n",
    "#     print(layer.data.shape)\n",
    "#     print(reshape_tensor.shape)\n",
    "\n",
    "    result.append(reshape_tensor)\n",
    "result = torch.cat(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1302a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1663370])\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d884424",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d596ba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05601a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3692de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e0b97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_model_mask(net: nn.Module, mask: torch.tensor) -> nn.Module:\n",
    "    list_of_reshaped_layers = []\n",
    "    list_of_shapes = []\n",
    "    for layer in net.parameters():\n",
    "        reshaped_layer = torch.flatten(layer.data)\n",
    "        list_of_reshaped_layers.append(reshaped_layer)\n",
    "        shape = reduce((lambda x, y: x * y), list(layer.data.shape))\n",
    "        list_of_shapes.append(shape)\n",
    "    cat_full_vec = torch.cat(reshape_list)\n",
    "    compressed_full_vec = torch.mul(cat_full_vec, mask)\n",
    "    \n",
    "    compressed_split_vec = torch.split(compressed_full_vec, list_of_shapes)\n",
    "    i = 0\n",
    "    for layer in net.parameters():\n",
    "        layer.data = compressed_split_vec[i]\n",
    "        i+=1\n",
    "    \n",
    "    return net\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feabe22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34d8f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "32\n",
      "51200\n",
      "64\n",
      "1605632\n",
      "512\n",
      "5120\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for layer in model.parameters():\n",
    "    shape = reduce((lambda x, y: x * y), list(layer.data.shape))\n",
    "    print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47d10aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(cat_full_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ff3db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1663370])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30134c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800, 32, 51200, 64, 1605632, 512, 5120, 10]\n",
      "1663370\n",
      "torch.Size([10])\n",
      "tensor([0., -0., 0., -0., -0., 0., 0., -0., 0., 0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., -0.,\n",
      "        -0., 0., 0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0., 0., 0., 0., 0., 0., -0., 0., 0., 0., 0., -0.,\n",
      "        0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., -0., -0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0.,\n",
      "        -0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., 0.,\n",
      "        0., 0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., 0., 0., -0., 0., 0., -0., -0.,\n",
      "        -0., -0., -0., 0., 0., 0., -0., -0., 0., 0., 0., -0., -0., 0., 0., -0., -0., -0., 0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., -0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., 0., 0.,\n",
      "        0., -0., 0., 0., 0., -0., 0., 0., 0., -0., -0., -0., -0., 0., -0., 0., -0., 0., 0., 0., -0., 0., 0., 0.,\n",
      "        0., -0., -0., 0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., 0., 0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., -0., 0., -0., 0., 0., 0., 0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., -0., -0., -0., -0., 0., 0., 0., -0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., 0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., 0., -0., 0., -0., 0., 0., 0., -0.,\n",
      "        0., 0., -0., 0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0., 0., -0., 0., -0., -0., 0., -0., 0., 0., -0.,\n",
      "        0., 0., 0., -0., -0., 0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0.,\n",
      "        0., 0., -0., 0., 0., -0., 0., -0., -0., 0., 0., 0., 0., -0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0.,\n",
      "        0., 0., -0., -0., 0., -0., -0., 0., -0., 0., -0., -0., 0., 0., -0., 0., -0., 0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., -0., 0., 0., -0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0.,\n",
      "        -0., -0., 0., -0., -0., 0., -0., 0., 0., -0., -0., 0., 0., -0., 0., 0., -0., -0., 0., -0., -0., -0., 0., -0.,\n",
      "        -0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0., 0., 0., -0., 0., 0., 0., -0., 0., 0., 0., -0., -0.,\n",
      "        -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., -0., 0., 0., -0., 0., -0., 0., -0., 0., -0., -0., -0.,\n",
      "        -0., 0., -0., -0., -0., -0., 0., -0., -0., -0., -0., -0., 0., 0., -0., 0., 0., -0., -0., 0., 0., 0., -0., 0.,\n",
      "        0., 0., 0., -0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., -0., 0., -0.,\n",
      "        0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., -0., 0., -0., 0., -0., 0., 0., -0.,\n",
      "        0., -0., 0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., -0., 0., 0., -0.,\n",
      "        -0., -0., 0., -0., -0., -0., 0., 0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0.,\n",
      "        0., -0., -0., 0., 0., -0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., -0., 0., 0., -0., -0.,\n",
      "        -0., 0., 0., -0., -0., 0., -0., 0., 0., -0., 0., 0., -0., 0., 0., 0., 0., 0., -0., 0., 0., -0., -0., 0.,\n",
      "        -0., -0., 0., 0., 0., -0., 0., 0., 0., -0., -0., -0., -0., 0., 0., -0., -0., -0., 0., 0., 0., 0., -0., -0.,\n",
      "        0., 0., -0., -0., -0., 0., -0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., 0., 0., -0.,\n",
      "        0., 0., 0., -0., 0., -0., -0., 0., -0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., 0., 0., 0., 0., 0.,\n",
      "        0., -0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0., 0., -0., 0., 0., -0., 0., -0., -0., 0., -0.,\n",
      "        0., -0., 0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0., -0., 0., -0., 0., 0., 0., -0., 0., -0., -0., -0.,\n",
      "        0., 0., 0., 0., 0., -0., -0., 0.])\n",
      "tensor([-0., -0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., 0., -0., 0., -0., 0.,\n",
      "        0., -0., 0., -0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([-0., -0., -0., 0., 0., 0., -0., 0., -0., 0., -0., -0., -0., -0., 0., -0., -0., -0., 0., 0., 0., -0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., -0., 0., -0., 0., -0., -0., 0., 0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0.,\n",
      "        -0., -0., 0., 0., 0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., -0.])\n",
      "tensor([-0., 0., 0.,  ..., -0., 0., 0.])\n",
      "tensor([-0., 0., -0., 0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0., -0., 0., -0., -0., -0., 0., 0., -0., -0.,\n",
      "        -0., -0., 0., -0., -0., -0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., -0., -0., 0.,\n",
      "        -0., -0., -0., 0., -0., 0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0.,\n",
      "        0., 0., -0., -0., -0., 0., 0., 0., 0., 0., -0., 0., -0., -0., -0., 0., 0., -0., 0., -0., 0., -0., -0., -0.,\n",
      "        0., 0., 0., -0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., -0., 0., 0., -0., -0.,\n",
      "        0., 0., -0., 0., 0., 0., 0., 0., -0., -0., 0., -0., -0., 0., 0., 0., 0., -0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., 0., -0., 0., 0., 0., 0., -0., 0., 0., 0., -0., -0., -0., 0., -0., 0., -0., -0., 0., -0., 0., 0., -0.,\n",
      "        -0., 0., 0., 0., 0., 0., -0., -0., 0., 0., -0., -0., 0., -0., -0., -0., -0., -0., -0., 0., 0., -0., -0., 0.,\n",
      "        -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., -0., 0., -0., 0., -0., -0., -0., -0., -0., 0., 0., 0., -0.,\n",
      "        -0., -0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., -0., 0., -0., -0., -0., 0., 0., 0.,\n",
      "        0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., -0., 0., 0., 0., 0., -0., -0., 0., -0., -0., -0., 0.,\n",
      "        -0., 0., 0., -0., -0., -0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., -0., 0., 0., 0., 0., -0.,\n",
      "        0., -0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., 0., -0., -0., 0., -0., -0., -0., 0., -0., 0., -0., -0.,\n",
      "        0., 0., -0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., 0., -0., -0., 0., -0., 0., -0., 0.,\n",
      "        -0., 0., -0., -0., 0., -0., -0., 0., -0., -0., 0., 0., -0., 0., -0., -0., -0., 0., 0., -0., -0., 0., -0., 0.,\n",
      "        0., -0., -0., 0., 0., 0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., 0., -0., 0., 0., -0., 0., 0., -0.,\n",
      "        -0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., -0., -0., -0., 0., 0., 0., -0., 0., 0., -0.,\n",
      "        -0., 0., -0., -0., -0., 0., 0., -0., -0., 0., 0., -0., 0., -0., -0., 0., -0., 0., -0., 0., -0., 0., -0., -0.,\n",
      "        0., -0., 0., 0., 0., -0., -0., 0., 0., 0., -0., 0., 0., 0., 0., 0., 0., -0., -0., -0., 0., 0., 0., -0.,\n",
      "        0., -0., -0., 0., -0., 0., 0., 0., -0., 0., 0., -0., 0., 0., 0., -0., -0., 0., -0., -0., 0., -0., 0., -0.,\n",
      "        0., 0., 0., 0., -0., 0., 0., -0., 0., -0., -0., -0., -0., 0., 0., 0., -0., 0., 0., 0., -0., 0., -0., -0.,\n",
      "        0., -0., 0., -0., 0., -0., 0., -0.])\n",
      "tensor([0., -0., -0.,  ..., 0., 0., 0.])\n",
      "tensor([-0., -0., 0., -0., 0., -0., -0., -0., -0., 0.])\n"
     ]
    }
   ],
   "source": [
    "list_of_reshaped_layers = []\n",
    "list_of_shapes = []\n",
    "for layer in model.parameters():\n",
    "    reshaped_layer = torch.flatten(layer.data)\n",
    "    list_of_reshaped_layers.append(reshaped_layer)\n",
    "    shape = reduce((lambda x, y: x * y), list(layer.data.shape))\n",
    "    list_of_shapes.append(shape)\n",
    "cat_full_vec = torch.cat(list_of_reshaped_layers)\n",
    "\n",
    "compressed_full_vec = torch.mul(cat_full_vec, mask)\n",
    "compressed_split_vec = torch.split(compressed_full_vec, list_of_shapes)\n",
    "i = 0\n",
    "for layer in model.parameters():\n",
    "    layer.data = compressed_split_vec[i]\n",
    "    i+=1\n",
    "    \n",
    "print(list_of_shapes)\n",
    "print(cat_full_vec.shape[0])\n",
    "print(compressed_split_vec[7].shape)\n",
    "for layer in model.parameters():\n",
    "    print(layer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1afc13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c6f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
